# DAG
全称Directed Acyclic Graph，简称DAG。工作流中的Task任务以有向无环图的形式组装起来，从入度为零的节点进行拓扑遍历，直到无后继节点为止。

# 流程定义
通过拖拽任务节点并建立任务节点的关联所形成的可视化DAG

# 流程实例
流程实例是流程定义的实例化，可以通过手动启动或定时调度生成,流程定义每运行一次，产生一个流程实例

# 任务实例
任务实例是流程定义中任务节点的实例化，标识着具体的任务执行状态

# 任务类型
目前支持有SHELL、SQL、SUB_PROCESS(子流程)、PROCEDURE、MR、SPARK、PYTHON、DEPENDENT(依赖)、，同时计划支持动态插件扩展，注意：其中子 SUB_PROCESS 也是一个单独的流程定义，是可以单独启动执行的

# 调度方式
系统支持基于cron表达式的定时调度和手动调度。命令类型支持：启动工作流、从当前节点开始执行、恢复被容错的工作流、恢复暂停流程、从失败节点开始执行、补数、定时、重跑、暂停、停止、恢复等待线程。 其中 恢复被容错的工作流 和 恢复等待线程 两种命令类型是由调度内部控制使用，外部无法调用

# 定时调度
系统采用 quartz 分布式调度器，并同时支持cron表达式可视化的生成

# 依赖：
系统不单单支持 DAG 简单的前驱和后继节点之间的依赖，同时还提供任务依赖节点，支持流程间的自定义任务依赖

# 优先级 
支持流程实例和任务实例的优先级，如果流程实例和任务实例的优先级不设置，则默认是先进先出

# 邮件告警
支持 SQL任务 查询结果邮件发送，流程实例运行结果邮件告警及容错告警通知

# 失败策略
对于并行运行的任务，如果有任务失败，提供两种失败策略处理方式，继续是指不管并行运行任务的状态，直到流程失败结束。结束是指一旦发现失败任务，则同时Kill掉正在运行的并行任务，流程失败结束

# 补数
补历史数据，支持区间并行和串行两种补数方式

# 任务状态统计
在指定时间范围内，统计任务实例中状态为提交成功、正在运行、准备暂停、暂停、准备停止、停止、失败、成功、需要容错、kill、等待线程的个数

# 流程状态统计
在指定时间范围内，统计工作流实例中状态为提交成功、正在运行、准备暂停、暂停、准备停止、停止、失败、成功、需要容错、kill、等待线程的个数

# 工作流定义统计
统计用户创建的工作流定义及管理员授予该用户的工作流定义

# Shell节点
shell节点，在worker执行的时候，会生成一个临时shell脚本，使用租户同名的linux用户执行这个脚本。

# 子流程节点
子流程节点，就是把外部的某个工作流定义当做一个任务节点去执行。

# 依赖节点
依赖节点，就是依赖检查节点。比如A流程依赖昨天的B流程执行成功，依赖节点会去检查B流程在昨天是否有执行成功的实例。

# 存储过程节点
根据选择的数据源，执行存储过程。

# SPARK节点
通过SPARK节点，可以直接直接执行SPARK程序，对于spark节点，worker会使用spark-submit方式提交任务

# MapReduce(MR)节点
使用MR节点，可以直接执行MR程序。对于mr节点，worker会使用hadoop jar方式提交任务

# Python节点
使用python节点，可以直接执行python脚本，对于python节点，worker会使用python **方式提交任务。

# Pigeon节点
Pigeon任务类型与通过调用远程websocket服务，实现远程任务的触发，状态、日志的获取，是 DolphinScheduler 通用远程 websocket 服务调用任务.

# Conditions节点
Conditions是一个条件节点，根据上游任务运行状态，判断应该运行哪个下游任务。截止目前Conditions支持多个上游任务，但只支持两个下游任务。当上游任务数超过一个时，可以通过且以及或操作符实现复杂上游依赖

# Standalone极速体验版
Standalone 仅适用于 DolphinScheduler 的快速体验.

# 伪集群部署
伪集群部署目的是在单台机器部署 DolphinScheduler 服务，该模式下master、worker、api server、logger server都在同一台机器上

# 集群部署
集群部署目的是在多台机器部署 DolphinScheduler 服务，用于运行大量任务情况。

# Kubernetes 部署
Kubernetes部署目的是在Kubernetes集群中部署 DolphinScheduler 服务，能调度大量任务，可用于在生产中部署。
