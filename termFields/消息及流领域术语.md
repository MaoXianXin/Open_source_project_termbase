# messaging-term

## 消息架构 

**消息集群**：为消息服务提供集群级别的高可用能力，可分为生产者集群、消费者集群和消息服务器集群。
- 生产者集群

用来表示发送消息的应用，一个生产者集群下包含多个生产者实例，可以是多台机器，也可以是一台机器的多个进程，或者一个进程的多个生产者对象。
- 消费者集群

用来表示消费消息的应用，一个消费者集群下包含多个消费者实例，可以是多台机器，也可以是多个进程，或者是一个进程的多个消费者对象。支持以push、pull拉两种模式对消息进行消费，同时也支持集群方式和广播方式的消费。

- 消息服务器集群：
	- 消息代理集群：作为消息中转角色，负责存储、转发消息。消息代理集群可指定为不同分组，不同分组间物理隔离，可随时对一组或多组消息代理集群进行启用、禁用操作。一组消息代理集群被禁用后，流量将自动从这组集群切走，从而隔离这组集群对整个消息服务器集群的影响。只要有一组消息代理集群正常提供服务，消息服务器集群仍可正常对外提供服务。
	- 名字服务集群：提供路由信息，更新和发现消息代理服务。每个名字服务实例拥有所有的路由信息，包括所有的消息代理实例信息、数据信息等 。只要有一个名字服务实例正常提供服务，就不会影响消息服务器集群的稳定性。整个名字服务集群不可用时，原有的生产者和消费者仍可正常运作。

**租户**

一套消息服务器集群能为多个用户提供服务，不同用户之间的资源可实现相互隔离。通过在多个租户之间复用消息服务器集群的系统资源，可以有效节省系统成本。

**消息轨迹**

一条消息从生产者发送到消息服务器、再到消费者消费处理，这整个过程中的各个相关节点的时间、状态等数据汇聚而成的完整链路信息，称为消息轨迹。消息服务自身提供开箱即用、端到端的消息轨迹支持，为排查问题提供强有力的数据支撑。生产者、消费者群和消息服务器可分别启用或禁用消息轨迹功能。

**发布-订阅模型**

消息生产者应用创建Topic并将消息发送到Topic。消费者应用创建对Topic的订阅以便从其接收消息。通信可以是一对多（扇出）、多对一（扇入）和多对多。

## 发送者
### 同步发送

同步发送是指在调用发送消息的接口后，阻塞流程直到发送返回发送结果。

### 异步发送

异步发送是指在调用发送消息的接口后，不阻塞流程，而是让发送结果返回后自动触发回调执行后续操作。

### oneway发送

Oneway发送是指在调用发送消息的接口后，既不阻塞流程，也不做后续操作。

### 批量发送

在调用发送接口前，可以将多条消息一次性传入，用于提高发送的吞吐量，降低时延。

### MessageQueueSelector（队列选择器）

在调用发送接口时，可以使用MessageQueueSelector投递到Topic下指定的queue，可用于实现顺序消息和负载均衡。

### 生产者集群

具有相同GroupName的生产者被视为在同一个生产者集群内。


### 事务消息流程
- step1：发送半消息(预处理消息)
 半消息(预处理消息)：一种特殊的消息类型，该状态的消息暂时不能被Consumer消费。此时消息已经到达服务端，但是被打上了“暂不能投递”的标记。

- step2：发送二次确认消息
 Commit（提交）：本次事务执行成功后发送的确认消息；服务端收到后将半消息标记为可投递，并投递给消费者。
 Rollback（回滚）：本次事务执行失败后发送的确认消息；服务端收到后将半消息标记为失败，不投递给消费者。

### 事务消息回查流程
- step1：服务端发起回查请求
 若服务端接收到到半消息后，出现断网或者是生产者应用重启的特殊情况，未在超时时间内收到二次确认消息。此时会随机挑选该半消息的发送集群中的任一实例，执行回查。

- step2：生产者应答回查请求
 在收到回查请求的生产者检查事务状态后，发送Commit或Rollback的二次确认消息（与事务消息流程的step2类似）。

## 消息
### 普通消息

普通消息是指消息队列无特性的消息，用来区别于有特性的定时和延时消息、顺序消息和事务消息。

### 顺序消息

顺序消息是消息队列提供的一种对消息发送和消费顺序有严格要求的消息。对于一个指定的Topic，消息严格按照先进先出（FIFO）的原则进行消息发布和消费，即先发布的消息先消费，后发布的消息后消费。
顺序消息分为分区顺序消息和全局顺序消息。

- 分区顺序消息

  对于指定的一个Topic，所有消息根据消息Key进行区块分区，同一个分区内的消息按照严格的先进先出（FIFO）原则进行发布和消费。同一分区内的消息保证顺序，不同分区之间的消息顺序不做要求。

- 全局顺序消息

  对于指定的一个Topic，所有消息按照严格的先入先出（FIFO）的顺序来发布和消费。

### 定时消息

生产者将消息发送到消息队列服务端，但并不期望立马投递这条消息，而是推迟到在当前时间点之后的某一个时间投递到消费者进行消费，该消息即定时消息；发送定时消息需要明确指定消息发送时间点之后的某一时间点作为消息投递的时间点。

### 延迟消息

生产者将消息发送到消息队列服务端，但并不期望立马投递这条消息，而是延迟一定时间后才投递到消费者进行消费，该消息即延时消息；发送延时消息时需要设定一个延时时间长度，消息将从当前发送时间点开始延迟固定时间之后才开始投递。

### 事务消息

消息队列提供类似XA或Open XA的分布式事务功能，通过消息队列事务消息能达到分布式事务的最终一致。

### 消息标签(tag)

用来进一步区分某个Topic下的消息分类，消息从生产者发出即带上的属性。针对消息分类，可以选择创建多个Topic，或者在同一个Topic下创建多个Tag。但通常情况下，不同的Topic之间的消息没有必然的联系，而Tag则用来区分同一个Topic下相互关联的消息，例如全集和子集的关系、流程先后的关系。

## 消费者
- 消费者

消费者订阅主题，当主题中有消息产生时，消费者能够获取到新消息。

- 消费组

属于同一组消费者的ID标识，使用同一消费组名的消费者属于同一个组，同一个消费组的全部消费者按照约定的负载均衡模式分配自己负责的队列分区。例如在集群消费模式且采用Push消费或Pull消费时，每个消费者持有部分队列且不重复，同一个消费组的全部消费者持有的队列总和为订阅主题的全部队列。

- 消费者标识

每个消费者运行时唯一分配的命名ID，用于区分不同的消费者连接，消费者标识可以确保在同一个消费组下全局唯一。

- 负载均衡模式

消费者的负载均衡工作模式，分为集群消费、广播消费。

- 集群消费

通常情况下，消费主题中的每一条消息，只会被同一个消费组中的一个消费者消费。

- 广播消费

通常情况下，针对消费主题中的每一条消息，只要是订阅了该消费主题的消费者进程都会消费到该消息一次。

- 负载均衡

同一消费组的消费者会划分消费主题队列，当消费主题队列数或同组消费者数发生变化时，会重新进行一次主题队列的划分操作，该过程称为负载均衡。

- 消费位点

标识某一消费组对于某一队列当前的消费位置，消费者重启或下线，重新接替该队列的消费者会从上次位置开始继续消费。

- 消费位点提交

消费者在消费过程中，主动或被动的保存当前队列的消费位点信息到服务端的过程，方便消费者重启继续上次消费位点开始消费。

- 消费位点方式

首次启动某一消费组的消费者时，消费者默认从队列的什么位置开始消费数据，包括：最大位置消费、最小位点消费。

- Push消费

Push消费模式只需在回调方法中写好业务逻辑即可，新消息拉取、消费位点提交均在SDK封装完成。Push模式会进行负载均衡，同一消费组内某一消费者进程会持有部分队列，持有的队列其他消费者进程无法消费。

- Pull消费

Pull消费模式需要主动调用拉取操作获取新消息，消息处理完成后主动调用确认操作完成消费。Pull模式会进行负载均衡，同一消费组内某一消费者进程会持有部分队列，持有的队列其他消费者进程无法消费。

- Pop消费

Pop消费与Push/Pull消费的区别是消费者不持有队列，同一消费组中的消费者地位均等、无状态，无需对消费者进行负载均衡。

- 过滤消费

消费者只处理符合过滤条件的消息，过滤条件的表达形式通常有TAG、SQL等。

- exactly once

集群消费模式下，同一条消息，被同一消费组的消费者消费且仅消费一次。

- at most once

集群消费模式下，同一条消息，被同一消费组的消费者最多消费一次。

- at lease once

集群消费模式下，同一条消息，被同一消费组的消费者最少消费一次。

## 订阅关系
-- 突出tag 二级消息订阅
- Subscription(订阅关系)
基于发布-订阅模型(Pub/Sub)的消息系统中，消费者，即消息的订阅方订阅关注的Topic，以获取并消费消息，消费者中消费分组和其关注的Topic列表之间的组合关系，称之为订阅关系。
- 订阅关系一致
同一个消费者分组下所有消费者所订阅的Topic、Tag完全一致
- 广播消费
消费分组内的消费者处于同等关系，将每条消息推送给分组内所有注册过的消费者，保证消息至少被每个消费者消费一次。
- 集群消费
消费分组内的消费者处于负载均衡关系，任意一条消息只需要被消费分组内的任意一个消费者处理即可。
- Tag(消息标签)
某个Topic下的消息进行分类，生产者在发送消息时指定消息的Tag，消费者可以根据已经指定的Tag来进行订阅。Topic与Tag都是业务上用来归类的标识，区分在于Topic是一级分类，而Tag可以理解为是二级分类。可以通过Tag来实现消息过滤。
- Tag过滤
消费者订阅的Tag和发送者设置的消息Tag一致时，则消息被投递给消费端进行消费。
- SQL过滤
消费者订阅符合SQL92规范的过滤计算条件，服务端按照过滤条件匹配消息属性值，过滤出符合条件的消息分配给消费者进行处理。


## Topic
- Topic（主题）

在 Pub/Sub 模型中，用于封装消息传递的目标标识的受管对象，是消息发送中转的逻辑地址，Topic内部由多个队列(MessageQueue 或者 Partition )组成，
不同的业务类型使用不同的消息 Topic 来隔离和区分，且不同场景使用不同类型Topic, 比如事务 Topic，普通 Topic 。

- 事务 Topic

区别与普通Topic，该 Topic 是某一类型事务消息的逻辑地址，该 Topic 中的消息有可能被提交或者回滚，只有提交的消息才会被下游的消费者所消费。

- 消息分区（MessageQueue 或 Partition）

定义消息存储的物理单元，常用于提升消息发送存储的并发度，一个 Topic 的多个分区会分布在多个broker 上面，用户可以独立操作分区，其中分区根据设计又可分为静态分区与动态分区。

- 动态分区

此种类型的消息分区均匀的分散在集群的所有 broker 上面，在 broker 扩缩容的过程中，分区数量会随着 broker 的增减而增减。

- 静态分区

此种类型的消息分区只会分布在集群的某些 broker 上面，在 broker 扩缩容的过程中，分区数量会保持固定，不随 broker 数量的增减而变化。

- 
## broker & Nameserver
**NameServer**

MQ的注册中心和路由中心，是实现消息服务弹性部署和线性扩展的核心。nameserver类似于kafka中的zookeeper，但相比于zookeeper更加轻量级，是无状态的元数据服务集群，使MQ摆脱了对外部中间件的依赖，降低维护成本。
- 服务注册：broker与所有nameServer节点建立长连接，定时将topic信息注册到所有nameServer，nameServer管理broker注册的元数据并对外暴露消息服务。
- 服务路由：生产者与消费者与nameServer某一节点建立长连接，定时从nameServer同步topic路由信息，通过topic路由信息查找到具体的broker地址进行消息的收发。
- 心跳检查：nameServer监听与所有组件的长连接，当监听到长连接断开等异常事件时，扫描所有broker并通过心跳包判断出状态为不存活的broker，针对该broker删除nameServer上相应的元数据和路由信息。
- AP设计：nameServer集群中各个节点互相独立，彼此没有任何通信，也没有主从关系，不需要选主，单台节点挂掉不影响其他节点，通过牺牲强一致性来保障高可用性。

**Broker**

MQ的核心处理模块，负责消息的存储与中转，通过主从复制或多副本架构，提供高可用的消息服务能力。
- 存算一体：broker既提供消息的存储能力，将消息持久化到磁盘，支持消息堆积；同时也提供消息收发能力，支持高并发场景下的业务消息流转。
- 消息重试：若Consumer消费某条消息失败，broker会在一定时间间隔后，将消息重新投递给Consumer消费，若达到最大重试次数后消息仍消费失败，则消息将被投递至死信队列。
- 消息过滤：若Consumer只需要关注某一topic下的部分消息，可通过设置过滤条件，由broker支持基于tag、SQL属性等多种形式的消息过滤，以降低非必要的网络开销。
- 主从同步：消息写入Master节点之后，slave节点从Master节点复制消息，保持同步，包括消息实体和元数据的同步，从而保证多台机器上的数据冗余，避免消息丢失。
- 读写分离：broker具有独特的读写分离设计，包括读写权限的隔离、Master-slave读写分离、直接内存-虚拟内存读写分离。
	- Master-slave读写分离：读消息从Slave节点读取，写操作由Master节点处理，可以在Master节点负载较高时分担请求压力。
	- 直接内存-虚拟内存读写分离：读消息从page cache中读取，写消息先写到堆内存，通过异步刷盘定时提交到page cache，再持久化到磁盘，提升了整体读写性能。

## 消息存储 
- 消息日志

消息日志非应用日志那种非结构化文件，而是一种数据记录的抽象，它有顺序追加，全局有序等特点，每条日志记录对应唯一序号，用来索引日志位置，也能隐形地表达日志时间。每条日志记录一般对应一条消息（批处理中也可能对应多条消息），记录存储了元信息（消息所属Topic，tag等）以及消息数据。这种设计能够很好的和具体物理时钟解耦。
- 物理文件 

存储日志的载体，是存储日志内容的文件，一般按照固定大小滚动。
- 逻辑位点

消息在分区中顺序偏移。
- 物理位点

消息在物理文件中的地址。
- 提交位点 

消息可以对外暴露（客户端可见）的顺序偏移。
- 消费索引 

建立逻辑位点到消息物理地址之间的映射关系，方便快速定位消息所在的物理文件位置。消息中间件通常会有单独的文件来存储消息索引。
- 时间索引 

建立指定的时间戳（timestamp）或者时间范围与消息物理地址之间的映射关系，指定时间戳或者时间范围后可以快速定位消息所在的物理文件位置。
- 消息ID索引 

建立消息ID与消息物理地址之间的映射关系，指定消息ID后可以快速定位消息所在的物理文件位置。
- 批消息索引 

建立逻辑位点到一批消息物理地址之间的映射关系，方便快速定位一批消息所在的物理文件位置。通过批消息索引可以提高批量消息的吞吐。
- 日志删除 

按照一定的保留策略直接删除不符合条件的日志分段。
- 日志压缩 

针对每个消息的 key 进行整合，对于有相同 key 的不同 value 值，只保留最后一个版本。
## Streaming

- namespace

命名空间，为任务提供逻辑隔离，相同namespace，相同pipelineName的进程实例，共同协作完成一个任务，相同namespace的任务可以跑在一个进程里，可以共享配置。

- pipelineName

任务名称，管理分配配置的单元。
- source

数据来源，由source流向rocketmq-streams。
- sink

数据去向，由rocketmq-streams流向sink。
- 事件时间

流计算引擎按照数据本身的时间，来计算时间归属，与之对应的是处理时间。
- 处理时间

流计算引擎按照算子处理这条数据的时间来计算时间归属。
- 窗口

计算过程，将无界的数据流按时间划分为有界的区间，按照这个区间统计数据。有滑动窗口、滚动窗口、会话窗口。

- 滑动窗口

滑动窗口也被称作Sliding Window。不同于滚动窗口的窗口不重叠，滑动窗口的窗口可以重叠。滑动窗口有size和slide两个参数。size为窗口的大小，slide为每次滑动的步长。
- 滚动窗口

滚动窗口（TUMBLE）将每个元素分配到一个指定大小的窗口中。通常，滚动窗口有一个固定的大小，并且不会出现重叠。例如，如果指定了一个5分钟大小的滚动窗口，无限流的数据会根据时间划分为[0:00, 0:05)、[0:05, 0:10)、[0:10, 0:15)等窗口。
- 会话窗口

会话窗口（SESSION）通过SESSION活动来对元素进行分组。会话窗口与滚动窗口和滑动窗口相比，没有窗口重叠，没有固定窗口大小。相反，当它在一个固定的时间周期内不再收到元素，即会话断开时，该窗口就会关闭。
会话窗口通过一个间隔时间（Gap）来配置，这个间隔定义了非活跃周期的长度。例如，一个表示鼠标单击活动的数据流可能具有长时间的空闲时间，并在两段空闲之间散布着高浓度的单击。如果数据在指定的间隔（Gap）之后到达，则会开始一个新的窗口。
- 状态

在带窗口计算过程中，需要将之前计算结果保存起来，以便在后续计算过程中使用，在时间达到窗口触发条件时触发。例如对1分钟内数据进行加和，需要将这1分钟内各个时刻数据累加，并保存结果，这个结果就是状态。
- 算子

流计算中处理数据的各种方式，例如map,split,filter,join,window,sum等等。
- checkpoint

实时计算提供可以恢复数据流应用到一致状态的容错机制（CheckPoint）。容错机制的核心就是持续创建分布式数据流及其状态的一致快照。这些快照在系统遇到故障时，充当可以回退的一致性检查点（checkpoint）
- watermark

计算引擎处理数据的顺序不一定就是数据的产生的顺序，含义是所有时间戳t'< t的事件已经全部发生。如果t（Watermark）已经生效，则后续Event Time小于t的记录将全部丢弃（支持用户配置，使事件时间小于t的数据可以更新）。
- exactly-once

精确计算一次，保证数据的结果对sink只产生一次影响。
## Connect 
- RocketMQ Connect

为RocketMQ提供数据集成能力，可从其它数据系统读取数据到RocketMQ，也可以从RocketMQ消费数据写入其它数据系统。
具有及时性，可靠性，高性能，低代码，扩展性强等特点。
借助RocketMQ解耦上下游，无需考虑反压问题，可实现N:1,1:N的数据复制能力。

通过RocketmMQ从源数据系统复制数据到目标系统，主要包括连接器Source Connector，Sink Connector，运行时Runtime。

- Connector 
  连接器，定义如何创建一个具体的连接器，sink或者source，接收worker进程传来的连接器配置数据，并对任务拆分，将配置传递给每个子任务。
  例如MySql Source Connector,复制MySql的表数据到RocketMQ，首先确定所需负载表的范围，同时确定需要执行的任务数，然后为每个任务分配所系配置,
  通过taskConfigs返回每个Task运行所需的详细配置，配置包含需要处理的表，jdbc相关配置等。Worker进程根据Connector定义的任务类型，和任务配置，启动具体的任务运行。
  
- Source Connector

从源数据系统发送数据到RocketMQ，例如从mysql读数据到RocketMQ。Source Connector通过原系统的api解析事件数据例如解析MySql binlog，并将解析到的数据通过发送者将数据发送到RocketMQ，发送成功后Worker进程记录进度，并同步给集群其它Worker。

- Sink Connector

从RocketMQ消费数据写入到目标系统，例如RocketMQ写入到odps。Sink Connector启动消费者，从RocketMQ消费数据，并写入目标数据系统，写入成功提交消费位点。

- Task
实际负载处理其它数据系统与RocketMQ之间的数据写入，写出。连接器任务划分的最小单位。Task由Worker进程创建，初始化Task过程中会赋予上线文，Task通过上下文与Worker交互，例如Source Task从上下文读取最新的处理位点，Sink Task从上下文获取所需处理的queue信息等。
  
- Runtime
Connector运行时,为Connector提供运行和调度能力，支持单机或者集群方式部署，动态或者静态加载Soource/Sink Connector,提供服务发现，配置同步，高可用，故障处理，动态扩缩容等能力，同时提供RESTful接口方便管理Connector生命周期。

- Worker
Connector和Task运行"容器"，负责处理HTTP请求，例如新增Connector，关闭Connector等，同时传递保存Connector和Task所需配置。如果 Worker进程挂了，集群中其它Worker通过负载均衡可以接管改进程所有Connector和Task，通过Worker建的配置通过，位点同步，该Worker的Connector和Task可以无缝在集群中其它
Worker中继续运行。


、
